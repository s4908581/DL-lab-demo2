{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yvUw9hGgTdqq",
        "outputId": "1bbea5e7-b9a0-4085-8be6-7f5f63f4de92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Using device: cuda\n",
            "GPU: NVIDIA A100-SXM4-40GB\n",
            "FastCIFARNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): DepthwiseSeparableConv(\n",
            "        (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
            "        (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): DepthwiseSeparableConv(\n",
            "        (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
            "        (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "      (se): SEBlock(\n",
            "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "        (fc): Sequential(\n",
            "          (0): Linear(in_features=64, out_features=4, bias=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Linear(in_features=4, out_features=64, bias=True)\n",
            "          (3): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): DepthwiseSeparableConv(\n",
            "        (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
            "        (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): DepthwiseSeparableConv(\n",
            "        (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
            "        (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "      (se): SEBlock(\n",
            "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "        (fc): Sequential(\n",
            "          (0): Linear(in_features=64, out_features=4, bias=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Linear(in_features=4, out_features=64, bias=True)\n",
            "          (3): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (2): BasicBlock(\n",
            "      (conv1): DepthwiseSeparableConv(\n",
            "        (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
            "        (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): DepthwiseSeparableConv(\n",
            "        (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
            "        (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "      (se): SEBlock(\n",
            "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "        (fc): Sequential(\n",
            "          (0): Linear(in_features=64, out_features=4, bias=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Linear(in_features=4, out_features=64, bias=True)\n",
            "          (3): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (3): BasicBlock(\n",
            "      (conv1): DepthwiseSeparableConv(\n",
            "        (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
            "        (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): DepthwiseSeparableConv(\n",
            "        (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
            "        (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "      (se): SEBlock(\n",
            "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "        (fc): Sequential(\n",
            "          (0): Linear(in_features=64, out_features=4, bias=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Linear(in_features=4, out_features=64, bias=True)\n",
            "          (3): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (4): BasicBlock(\n",
            "      (conv1): DepthwiseSeparableConv(\n",
            "        (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
            "        (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): DepthwiseSeparableConv(\n",
            "        (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
            "        (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "      (se): SEBlock(\n",
            "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "        (fc): Sequential(\n",
            "          (0): Linear(in_features=64, out_features=4, bias=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Linear(in_features=4, out_features=64, bias=True)\n",
            "          (3): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): DepthwiseSeparableConv(\n",
            "        (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
            "        (pointwise): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): DepthwiseSeparableConv(\n",
            "        (depthwise): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
            "        (pointwise): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (se): SEBlock(\n",
            "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "        (fc): Sequential(\n",
            "          (0): Linear(in_features=128, out_features=8, bias=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Linear(in_features=8, out_features=128, bias=True)\n",
            "          (3): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): DepthwiseSeparableConv(\n",
            "        (depthwise): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
            "        (pointwise): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): DepthwiseSeparableConv(\n",
            "        (depthwise): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
            "        (pointwise): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "      (se): SEBlock(\n",
            "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "        (fc): Sequential(\n",
            "          (0): Linear(in_features=128, out_features=8, bias=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Linear(in_features=8, out_features=128, bias=True)\n",
            "          (3): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (2): BasicBlock(\n",
            "      (conv1): DepthwiseSeparableConv(\n",
            "        (depthwise): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
            "        (pointwise): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): DepthwiseSeparableConv(\n",
            "        (depthwise): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
            "        (pointwise): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "      (se): SEBlock(\n",
            "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "        (fc): Sequential(\n",
            "          (0): Linear(in_features=128, out_features=8, bias=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Linear(in_features=8, out_features=128, bias=True)\n",
            "          (3): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (3): BasicBlock(\n",
            "      (conv1): DepthwiseSeparableConv(\n",
            "        (depthwise): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
            "        (pointwise): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): DepthwiseSeparableConv(\n",
            "        (depthwise): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
            "        (pointwise): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "      (se): SEBlock(\n",
            "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "        (fc): Sequential(\n",
            "          (0): Linear(in_features=128, out_features=8, bias=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Linear(in_features=8, out_features=128, bias=True)\n",
            "          (3): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (4): BasicBlock(\n",
            "      (conv1): DepthwiseSeparableConv(\n",
            "        (depthwise): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
            "        (pointwise): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): DepthwiseSeparableConv(\n",
            "        (depthwise): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
            "        (pointwise): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "      (se): SEBlock(\n",
            "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "        (fc): Sequential(\n",
            "          (0): Linear(in_features=128, out_features=8, bias=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Linear(in_features=8, out_features=128, bias=True)\n",
            "          (3): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): DepthwiseSeparableConv(\n",
            "        (depthwise): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
            "        (pointwise): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): DepthwiseSeparableConv(\n",
            "        (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
            "        (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (se): SEBlock(\n",
            "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "        (fc): Sequential(\n",
            "          (0): Linear(in_features=256, out_features=16, bias=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Linear(in_features=16, out_features=256, bias=True)\n",
            "          (3): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): DepthwiseSeparableConv(\n",
            "        (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
            "        (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): DepthwiseSeparableConv(\n",
            "        (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
            "        (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "      (se): SEBlock(\n",
            "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "        (fc): Sequential(\n",
            "          (0): Linear(in_features=256, out_features=16, bias=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Linear(in_features=16, out_features=256, bias=True)\n",
            "          (3): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (2): BasicBlock(\n",
            "      (conv1): DepthwiseSeparableConv(\n",
            "        (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
            "        (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): DepthwiseSeparableConv(\n",
            "        (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
            "        (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "      (se): SEBlock(\n",
            "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "        (fc): Sequential(\n",
            "          (0): Linear(in_features=256, out_features=16, bias=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Linear(in_features=16, out_features=256, bias=True)\n",
            "          (3): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (3): BasicBlock(\n",
            "      (conv1): DepthwiseSeparableConv(\n",
            "        (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
            "        (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): DepthwiseSeparableConv(\n",
            "        (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
            "        (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "      (se): SEBlock(\n",
            "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "        (fc): Sequential(\n",
            "          (0): Linear(in_features=256, out_features=16, bias=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Linear(in_features=16, out_features=256, bias=True)\n",
            "          (3): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (4): BasicBlock(\n",
            "      (conv1): DepthwiseSeparableConv(\n",
            "        (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
            "        (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): DepthwiseSeparableConv(\n",
            "        (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
            "        (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "      (se): SEBlock(\n",
            "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "        (fc): Sequential(\n",
            "          (0): Linear(in_features=256, out_features=16, bias=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Linear(in_features=16, out_features=256, bias=True)\n",
            "          (3): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "  (fc): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (channel_shuffle): ChannelShuffle(groups=4)\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3556527638.py:175: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # 混合精度训练\n",
            "/tmp/ipython-input-3556527638.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Step [10/98], Loss: 1.9992\n",
            "Epoch [1/50], Step [20/98], Loss: 1.8740\n",
            "Epoch [1/50], Step [30/98], Loss: 1.7522\n",
            "Epoch [1/50], Step [40/98], Loss: 1.5828\n",
            "Epoch [1/50], Step [50/98], Loss: 1.5586\n",
            "Epoch [1/50], Step [60/98], Loss: 1.5524\n",
            "Epoch [1/50], Step [70/98], Loss: 1.4769\n",
            "Epoch [1/50], Step [80/98], Loss: 1.3996\n",
            "Epoch [1/50], Step [90/98], Loss: 1.4158\n",
            "Epoch [1/50] completed in 9.90s\n",
            "Training Loss: 1.6490, Test Accuracy: 50.71%\n",
            "Epoch [2/50], Step [10/98], Loss: 1.3458\n",
            "Epoch [2/50], Step [20/98], Loss: 1.2837\n",
            "Epoch [2/50], Step [30/98], Loss: 1.2342\n",
            "Epoch [2/50], Step [40/98], Loss: 1.2937\n",
            "Epoch [2/50], Step [50/98], Loss: 1.1973\n",
            "Epoch [2/50], Step [60/98], Loss: 1.1075\n",
            "Epoch [2/50], Step [70/98], Loss: 1.1821\n",
            "Epoch [2/50], Step [80/98], Loss: 1.0809\n",
            "Epoch [2/50], Step [90/98], Loss: 1.1562\n",
            "Epoch [2/50] completed in 10.00s\n",
            "Training Loss: 1.2043, Test Accuracy: 57.99%\n",
            "Epoch [3/50], Step [10/98], Loss: 1.0568\n",
            "Epoch [3/50], Step [20/98], Loss: 0.9519\n",
            "Epoch [3/50], Step [30/98], Loss: 1.0399\n",
            "Epoch [3/50], Step [40/98], Loss: 0.9122\n",
            "Epoch [3/50], Step [50/98], Loss: 1.0340\n",
            "Epoch [3/50], Step [60/98], Loss: 1.0862\n",
            "Epoch [3/50], Step [70/98], Loss: 0.9921\n",
            "Epoch [3/50], Step [80/98], Loss: 0.8660\n",
            "Epoch [3/50], Step [90/98], Loss: 0.9457\n",
            "Epoch [3/50] completed in 9.74s\n",
            "Training Loss: 0.9755, Test Accuracy: 62.88%\n",
            "Epoch [4/50], Step [10/98], Loss: 0.8677\n",
            "Epoch [4/50], Step [20/98], Loss: 0.8592\n",
            "Epoch [4/50], Step [30/98], Loss: 0.8863\n",
            "Epoch [4/50], Step [40/98], Loss: 0.8510\n",
            "Epoch [4/50], Step [50/98], Loss: 0.8848\n",
            "Epoch [4/50], Step [60/98], Loss: 0.7621\n",
            "Epoch [4/50], Step [70/98], Loss: 0.8207\n",
            "Epoch [4/50], Step [80/98], Loss: 0.8229\n",
            "Epoch [4/50], Step [90/98], Loss: 0.7341\n",
            "Epoch [4/50] completed in 9.79s\n",
            "Training Loss: 0.8151, Test Accuracy: 61.48%\n",
            "Epoch [5/50], Step [10/98], Loss: 0.6808\n",
            "Epoch [5/50], Step [20/98], Loss: 0.7028\n",
            "Epoch [5/50], Step [30/98], Loss: 0.7578\n",
            "Epoch [5/50], Step [40/98], Loss: 0.7729\n",
            "Epoch [5/50], Step [50/98], Loss: 0.7249\n",
            "Epoch [5/50], Step [60/98], Loss: 0.7108\n",
            "Epoch [5/50], Step [70/98], Loss: 0.5828\n",
            "Epoch [5/50], Step [80/98], Loss: 0.6767\n",
            "Epoch [5/50], Step [90/98], Loss: 0.6802\n",
            "Epoch [5/50] completed in 9.85s\n",
            "Training Loss: 0.7019, Test Accuracy: 60.11%\n",
            "Epoch [6/50], Step [10/98], Loss: 0.6442\n",
            "Epoch [6/50], Step [20/98], Loss: 0.4829\n",
            "Epoch [6/50], Step [30/98], Loss: 0.5631\n",
            "Epoch [6/50], Step [40/98], Loss: 0.7260\n",
            "Epoch [6/50], Step [50/98], Loss: 0.5305\n",
            "Epoch [6/50], Step [60/98], Loss: 0.7171\n",
            "Epoch [6/50], Step [70/98], Loss: 0.5904\n",
            "Epoch [6/50], Step [80/98], Loss: 0.6838\n",
            "Epoch [6/50], Step [90/98], Loss: 0.6478\n",
            "Epoch [6/50] completed in 9.78s\n",
            "Training Loss: 0.6179, Test Accuracy: 68.50%\n",
            "Epoch [7/50], Step [10/98], Loss: 0.5642\n",
            "Epoch [7/50], Step [20/98], Loss: 0.5593\n",
            "Epoch [7/50], Step [30/98], Loss: 0.5846\n",
            "Epoch [7/50], Step [40/98], Loss: 0.5121\n",
            "Epoch [7/50], Step [50/98], Loss: 0.4978\n",
            "Epoch [7/50], Step [60/98], Loss: 0.5862\n",
            "Epoch [7/50], Step [70/98], Loss: 0.5482\n",
            "Epoch [7/50], Step [80/98], Loss: 0.6486\n",
            "Epoch [7/50], Step [90/98], Loss: 0.5438\n",
            "Epoch [7/50] completed in 9.77s\n",
            "Training Loss: 0.5543, Test Accuracy: 70.29%\n",
            "Epoch [8/50], Step [10/98], Loss: 0.5569\n",
            "Epoch [8/50], Step [20/98], Loss: 0.4970\n",
            "Epoch [8/50], Step [30/98], Loss: 0.4917\n",
            "Epoch [8/50], Step [40/98], Loss: 0.5814\n",
            "Epoch [8/50], Step [50/98], Loss: 0.5389\n",
            "Epoch [8/50], Step [60/98], Loss: 0.5245\n",
            "Epoch [8/50], Step [70/98], Loss: 0.4752\n",
            "Epoch [8/50], Step [80/98], Loss: 0.5636\n",
            "Epoch [8/50], Step [90/98], Loss: 0.4940\n",
            "Epoch [8/50] completed in 10.07s\n",
            "Training Loss: 0.5102, Test Accuracy: 76.72%\n",
            "Epoch [9/50], Step [10/98], Loss: 0.3997\n",
            "Epoch [9/50], Step [20/98], Loss: 0.4527\n",
            "Epoch [9/50], Step [30/98], Loss: 0.4814\n",
            "Epoch [9/50], Step [40/98], Loss: 0.4787\n",
            "Epoch [9/50], Step [50/98], Loss: 0.4395\n",
            "Epoch [9/50], Step [60/98], Loss: 0.3783\n",
            "Epoch [9/50], Step [70/98], Loss: 0.4135\n",
            "Epoch [9/50], Step [80/98], Loss: 0.4129\n",
            "Epoch [9/50], Step [90/98], Loss: 0.4352\n",
            "Epoch [9/50] completed in 9.62s\n",
            "Training Loss: 0.4641, Test Accuracy: 72.53%\n",
            "Epoch [10/50], Step [10/98], Loss: 0.4408\n",
            "Epoch [10/50], Step [20/98], Loss: 0.4088\n",
            "Epoch [10/50], Step [30/98], Loss: 0.4215\n",
            "Epoch [10/50], Step [40/98], Loss: 0.4430\n",
            "Epoch [10/50], Step [50/98], Loss: 0.3698\n",
            "Epoch [10/50], Step [60/98], Loss: 0.4184\n",
            "Epoch [10/50], Step [70/98], Loss: 0.4785\n",
            "Epoch [10/50], Step [80/98], Loss: 0.4584\n",
            "Epoch [10/50], Step [90/98], Loss: 0.3934\n",
            "Epoch [10/50] completed in 9.74s\n",
            "Training Loss: 0.4349, Test Accuracy: 74.87%\n",
            "Epoch [11/50], Step [10/98], Loss: 0.4573\n",
            "Epoch [11/50], Step [20/98], Loss: 0.3592\n",
            "Epoch [11/50], Step [30/98], Loss: 0.4413\n",
            "Epoch [11/50], Step [40/98], Loss: 0.3559\n",
            "Epoch [11/50], Step [50/98], Loss: 0.4168\n",
            "Epoch [11/50], Step [60/98], Loss: 0.3925\n",
            "Epoch [11/50], Step [70/98], Loss: 0.4060\n",
            "Epoch [11/50], Step [80/98], Loss: 0.4226\n",
            "Epoch [11/50], Step [90/98], Loss: 0.3787\n",
            "Epoch [11/50] completed in 9.87s\n",
            "Training Loss: 0.4054, Test Accuracy: 83.28%\n",
            "Epoch [12/50], Step [10/98], Loss: 0.2815\n",
            "Epoch [12/50], Step [20/98], Loss: 0.3242\n",
            "Epoch [12/50], Step [30/98], Loss: 0.4161\n",
            "Epoch [12/50], Step [40/98], Loss: 0.3789\n",
            "Epoch [12/50], Step [50/98], Loss: 0.3147\n",
            "Epoch [12/50], Step [60/98], Loss: 0.3628\n",
            "Epoch [12/50], Step [70/98], Loss: 0.4017\n",
            "Epoch [12/50], Step [80/98], Loss: 0.3070\n",
            "Epoch [12/50], Step [90/98], Loss: 0.3802\n",
            "Epoch [12/50] completed in 10.12s\n",
            "Training Loss: 0.3769, Test Accuracy: 72.15%\n",
            "Epoch [13/50], Step [10/98], Loss: 0.2890\n",
            "Epoch [13/50], Step [20/98], Loss: 0.4052\n",
            "Epoch [13/50], Step [30/98], Loss: 0.3683\n",
            "Epoch [13/50], Step [40/98], Loss: 0.3428\n",
            "Epoch [13/50], Step [50/98], Loss: 0.3533\n",
            "Epoch [13/50], Step [60/98], Loss: 0.4137\n",
            "Epoch [13/50], Step [70/98], Loss: 0.2986\n",
            "Epoch [13/50], Step [80/98], Loss: 0.3547\n",
            "Epoch [13/50], Step [90/98], Loss: 0.3347\n",
            "Epoch [13/50] completed in 9.71s\n",
            "Training Loss: 0.3589, Test Accuracy: 75.11%\n",
            "Epoch [14/50], Step [10/98], Loss: 0.2830\n",
            "Epoch [14/50], Step [20/98], Loss: 0.3839\n",
            "Epoch [14/50], Step [30/98], Loss: 0.3729\n",
            "Epoch [14/50], Step [40/98], Loss: 0.3495\n",
            "Epoch [14/50], Step [50/98], Loss: 0.2835\n",
            "Epoch [14/50], Step [60/98], Loss: 0.3719\n",
            "Epoch [14/50], Step [70/98], Loss: 0.3839\n",
            "Epoch [14/50], Step [80/98], Loss: 0.3145\n",
            "Epoch [14/50], Step [90/98], Loss: 0.3101\n",
            "Epoch [14/50] completed in 9.70s\n",
            "Training Loss: 0.3428, Test Accuracy: 81.09%\n",
            "Epoch [15/50], Step [10/98], Loss: 0.2906\n",
            "Epoch [15/50], Step [20/98], Loss: 0.3138\n",
            "Epoch [15/50], Step [30/98], Loss: 0.3074\n",
            "Epoch [15/50], Step [40/98], Loss: 0.3232\n",
            "Epoch [15/50], Step [50/98], Loss: 0.2878\n",
            "Epoch [15/50], Step [60/98], Loss: 0.3563\n",
            "Epoch [15/50], Step [70/98], Loss: 0.3389\n",
            "Epoch [15/50], Step [80/98], Loss: 0.2804\n",
            "Epoch [15/50], Step [90/98], Loss: 0.3382\n",
            "Epoch [15/50] completed in 9.98s\n",
            "Training Loss: 0.3043, Test Accuracy: 81.99%\n",
            "Epoch [16/50], Step [10/98], Loss: 0.2275\n",
            "Epoch [16/50], Step [20/98], Loss: 0.3039\n",
            "Epoch [16/50], Step [30/98], Loss: 0.2833\n",
            "Epoch [16/50], Step [40/98], Loss: 0.3376\n",
            "Epoch [16/50], Step [50/98], Loss: 0.2010\n",
            "Epoch [16/50], Step [60/98], Loss: 0.3270\n",
            "Epoch [16/50], Step [70/98], Loss: 0.2901\n",
            "Epoch [16/50], Step [80/98], Loss: 0.3002\n",
            "Epoch [16/50], Step [90/98], Loss: 0.2367\n",
            "Epoch [16/50] completed in 9.71s\n",
            "Training Loss: 0.2949, Test Accuracy: 85.89%\n",
            "Epoch [17/50], Step [10/98], Loss: 0.3025\n",
            "Epoch [17/50], Step [20/98], Loss: 0.2455\n",
            "Epoch [17/50], Step [30/98], Loss: 0.2514\n",
            "Epoch [17/50], Step [40/98], Loss: 0.2310\n",
            "Epoch [17/50], Step [50/98], Loss: 0.2773\n",
            "Epoch [17/50], Step [60/98], Loss: 0.2445\n",
            "Epoch [17/50], Step [70/98], Loss: 0.2826\n",
            "Epoch [17/50], Step [80/98], Loss: 0.2969\n",
            "Epoch [17/50], Step [90/98], Loss: 0.2068\n",
            "Epoch [17/50] completed in 9.89s\n",
            "Training Loss: 0.2664, Test Accuracy: 86.35%\n",
            "Epoch [18/50], Step [10/98], Loss: 0.2299\n",
            "Epoch [18/50], Step [20/98], Loss: 0.2233\n",
            "Epoch [18/50], Step [30/98], Loss: 0.2447\n",
            "Epoch [18/50], Step [40/98], Loss: 0.3337\n",
            "Epoch [18/50], Step [50/98], Loss: 0.2037\n",
            "Epoch [18/50], Step [60/98], Loss: 0.2420\n",
            "Epoch [18/50], Step [70/98], Loss: 0.2517\n",
            "Epoch [18/50], Step [80/98], Loss: 0.3068\n",
            "Epoch [18/50], Step [90/98], Loss: 0.2417\n",
            "Epoch [18/50] completed in 9.75s\n",
            "Training Loss: 0.2508, Test Accuracy: 85.71%\n",
            "Epoch [19/50], Step [10/98], Loss: 0.2127\n",
            "Epoch [19/50], Step [20/98], Loss: 0.2412\n",
            "Epoch [19/50], Step [30/98], Loss: 0.2299\n",
            "Epoch [19/50], Step [40/98], Loss: 0.2328\n",
            "Epoch [19/50], Step [50/98], Loss: 0.1866\n",
            "Epoch [19/50], Step [60/98], Loss: 0.2339\n",
            "Epoch [19/50], Step [70/98], Loss: 0.2592\n",
            "Epoch [19/50], Step [80/98], Loss: 0.2702\n",
            "Epoch [19/50], Step [90/98], Loss: 0.2391\n",
            "Epoch [19/50] completed in 9.83s\n",
            "Training Loss: 0.2389, Test Accuracy: 83.47%\n",
            "Epoch [20/50], Step [10/98], Loss: 0.2170\n",
            "Epoch [20/50], Step [20/98], Loss: 0.2462\n",
            "Epoch [20/50], Step [30/98], Loss: 0.2176\n",
            "Epoch [20/50], Step [40/98], Loss: 0.2876\n",
            "Epoch [20/50], Step [50/98], Loss: 0.2112\n",
            "Epoch [20/50], Step [60/98], Loss: 0.1822\n",
            "Epoch [20/50], Step [70/98], Loss: 0.2405\n",
            "Epoch [20/50], Step [80/98], Loss: 0.2263\n",
            "Epoch [20/50], Step [90/98], Loss: 0.2436\n",
            "Epoch [20/50] completed in 9.72s\n",
            "Training Loss: 0.2224, Test Accuracy: 85.18%\n",
            "Epoch [21/50], Step [10/98], Loss: 0.1656\n",
            "Epoch [21/50], Step [20/98], Loss: 0.2620\n",
            "Epoch [21/50], Step [30/98], Loss: 0.1790\n",
            "Epoch [21/50], Step [40/98], Loss: 0.2030\n",
            "Epoch [21/50], Step [50/98], Loss: 0.1983\n",
            "Epoch [21/50], Step [60/98], Loss: 0.2258\n",
            "Epoch [21/50], Step [70/98], Loss: 0.2710\n",
            "Epoch [21/50], Step [80/98], Loss: 0.2201\n",
            "Epoch [21/50], Step [90/98], Loss: 0.1763\n",
            "Epoch [21/50] completed in 9.80s\n",
            "Training Loss: 0.2050, Test Accuracy: 88.32%\n",
            "Epoch [22/50], Step [10/98], Loss: 0.1951\n",
            "Epoch [22/50], Step [20/98], Loss: 0.1368\n",
            "Epoch [22/50], Step [30/98], Loss: 0.1738\n",
            "Epoch [22/50], Step [40/98], Loss: 0.2215\n",
            "Epoch [22/50], Step [50/98], Loss: 0.2019\n",
            "Epoch [22/50], Step [60/98], Loss: 0.1714\n",
            "Epoch [22/50], Step [70/98], Loss: 0.1724\n",
            "Epoch [22/50], Step [80/98], Loss: 0.2064\n",
            "Epoch [22/50], Step [90/98], Loss: 0.1932\n",
            "Epoch [22/50] completed in 9.78s\n",
            "Training Loss: 0.1952, Test Accuracy: 85.53%\n",
            "Epoch [23/50], Step [10/98], Loss: 0.1811\n",
            "Epoch [23/50], Step [20/98], Loss: 0.1773\n",
            "Epoch [23/50], Step [30/98], Loss: 0.1902\n",
            "Epoch [23/50], Step [40/98], Loss: 0.1692\n",
            "Epoch [23/50], Step [50/98], Loss: 0.2330\n",
            "Epoch [23/50], Step [60/98], Loss: 0.1738\n",
            "Epoch [23/50], Step [70/98], Loss: 0.1948\n",
            "Epoch [23/50], Step [80/98], Loss: 0.1810\n",
            "Epoch [23/50], Step [90/98], Loss: 0.1609\n",
            "Epoch [23/50] completed in 9.78s\n",
            "Training Loss: 0.1817, Test Accuracy: 89.42%\n",
            "Epoch [24/50], Step [10/98], Loss: 0.2578\n",
            "Epoch [24/50], Step [20/98], Loss: 0.1661\n",
            "Epoch [24/50], Step [30/98], Loss: 0.1363\n",
            "Epoch [24/50], Step [40/98], Loss: 0.1362\n",
            "Epoch [24/50], Step [50/98], Loss: 0.1443\n",
            "Epoch [24/50], Step [60/98], Loss: 0.1802\n",
            "Epoch [24/50], Step [70/98], Loss: 0.1812\n",
            "Epoch [24/50], Step [80/98], Loss: 0.1889\n",
            "Epoch [24/50], Step [90/98], Loss: 0.1661\n",
            "Epoch [24/50] completed in 9.72s\n",
            "Training Loss: 0.1659, Test Accuracy: 88.61%\n",
            "Epoch [25/50], Step [10/98], Loss: 0.1477\n",
            "Epoch [25/50], Step [20/98], Loss: 0.1486\n",
            "Epoch [25/50], Step [30/98], Loss: 0.1311\n",
            "Epoch [25/50], Step [40/98], Loss: 0.1507\n",
            "Epoch [25/50], Step [50/98], Loss: 0.1675\n",
            "Epoch [25/50], Step [60/98], Loss: 0.1159\n",
            "Epoch [25/50], Step [70/98], Loss: 0.1161\n",
            "Epoch [25/50], Step [80/98], Loss: 0.1574\n",
            "Epoch [25/50], Step [90/98], Loss: 0.1359\n",
            "Epoch [25/50] completed in 9.59s\n",
            "Training Loss: 0.1549, Test Accuracy: 87.91%\n",
            "Epoch [26/50], Step [10/98], Loss: 0.1500\n",
            "Epoch [26/50], Step [20/98], Loss: 0.1323\n",
            "Epoch [26/50], Step [30/98], Loss: 0.1767\n",
            "Epoch [26/50], Step [40/98], Loss: 0.1087\n",
            "Epoch [26/50], Step [50/98], Loss: 0.1437\n",
            "Epoch [26/50], Step [60/98], Loss: 0.1283\n",
            "Epoch [26/50], Step [70/98], Loss: 0.1292\n",
            "Epoch [26/50], Step [80/98], Loss: 0.1944\n",
            "Epoch [26/50], Step [90/98], Loss: 0.1871\n",
            "Epoch [26/50] completed in 9.57s\n",
            "Training Loss: 0.1456, Test Accuracy: 86.02%\n",
            "Epoch [27/50], Step [10/98], Loss: 0.1244\n",
            "Epoch [27/50], Step [20/98], Loss: 0.1626\n",
            "Epoch [27/50], Step [30/98], Loss: 0.1621\n",
            "Epoch [27/50], Step [40/98], Loss: 0.1166\n",
            "Epoch [27/50], Step [50/98], Loss: 0.1250\n",
            "Epoch [27/50], Step [60/98], Loss: 0.1457\n",
            "Epoch [27/50], Step [70/98], Loss: 0.1447\n",
            "Epoch [27/50], Step [80/98], Loss: 0.1364\n",
            "Epoch [27/50], Step [90/98], Loss: 0.1390\n",
            "Epoch [27/50] completed in 9.85s\n",
            "Training Loss: 0.1364, Test Accuracy: 89.11%\n",
            "Epoch [28/50], Step [10/98], Loss: 0.0891\n",
            "Epoch [28/50], Step [20/98], Loss: 0.1055\n",
            "Epoch [28/50], Step [30/98], Loss: 0.0905\n",
            "Epoch [28/50], Step [40/98], Loss: 0.1374\n",
            "Epoch [28/50], Step [50/98], Loss: 0.1191\n",
            "Epoch [28/50], Step [60/98], Loss: 0.1762\n",
            "Epoch [28/50], Step [70/98], Loss: 0.1257\n",
            "Epoch [28/50], Step [80/98], Loss: 0.1221\n",
            "Epoch [28/50], Step [90/98], Loss: 0.0994\n",
            "Epoch [28/50] completed in 9.85s\n",
            "Training Loss: 0.1205, Test Accuracy: 90.26%\n",
            "Epoch [29/50], Step [10/98], Loss: 0.0686\n",
            "Epoch [29/50], Step [20/98], Loss: 0.1214\n",
            "Epoch [29/50], Step [30/98], Loss: 0.0911\n",
            "Epoch [29/50], Step [40/98], Loss: 0.1234\n",
            "Epoch [29/50], Step [50/98], Loss: 0.1014\n",
            "Epoch [29/50], Step [60/98], Loss: 0.1285\n",
            "Epoch [29/50], Step [70/98], Loss: 0.1147\n",
            "Epoch [29/50], Step [80/98], Loss: 0.1344\n",
            "Epoch [29/50], Step [90/98], Loss: 0.0908\n",
            "Epoch [29/50] completed in 9.80s\n",
            "Training Loss: 0.1133, Test Accuracy: 87.92%\n",
            "Epoch [30/50], Step [10/98], Loss: 0.1076\n",
            "Epoch [30/50], Step [20/98], Loss: 0.0983\n",
            "Epoch [30/50], Step [30/98], Loss: 0.0808\n",
            "Epoch [30/50], Step [40/98], Loss: 0.1173\n",
            "Epoch [30/50], Step [50/98], Loss: 0.1055\n",
            "Epoch [30/50], Step [60/98], Loss: 0.1131\n",
            "Epoch [30/50], Step [70/98], Loss: 0.1223\n",
            "Epoch [30/50], Step [80/98], Loss: 0.1450\n",
            "Epoch [30/50], Step [90/98], Loss: 0.1241\n",
            "Epoch [30/50] completed in 9.83s\n",
            "Training Loss: 0.1007, Test Accuracy: 88.97%\n",
            "Epoch [31/50], Step [10/98], Loss: 0.1079\n",
            "Epoch [31/50], Step [20/98], Loss: 0.0829\n",
            "Epoch [31/50], Step [30/98], Loss: 0.1220\n",
            "Epoch [31/50], Step [40/98], Loss: 0.0958\n",
            "Epoch [31/50], Step [50/98], Loss: 0.0779\n",
            "Epoch [31/50], Step [60/98], Loss: 0.1224\n",
            "Epoch [31/50], Step [70/98], Loss: 0.0896\n",
            "Epoch [31/50], Step [80/98], Loss: 0.0702\n",
            "Epoch [31/50], Step [90/98], Loss: 0.0964\n",
            "Epoch [31/50] completed in 9.83s\n",
            "Training Loss: 0.0892, Test Accuracy: 90.49%\n",
            "Epoch [32/50], Step [10/98], Loss: 0.0696\n",
            "Epoch [32/50], Step [20/98], Loss: 0.0651\n",
            "Epoch [32/50], Step [30/98], Loss: 0.0603\n",
            "Epoch [32/50], Step [40/98], Loss: 0.0904\n",
            "Epoch [32/50], Step [50/98], Loss: 0.0631\n",
            "Epoch [32/50], Step [60/98], Loss: 0.0697\n",
            "Epoch [32/50], Step [70/98], Loss: 0.0776\n",
            "Epoch [32/50], Step [80/98], Loss: 0.1192\n",
            "Epoch [32/50], Step [90/98], Loss: 0.1000\n",
            "Epoch [32/50] completed in 9.86s\n",
            "Training Loss: 0.0760, Test Accuracy: 90.69%\n",
            "Epoch [33/50], Step [10/98], Loss: 0.0581\n",
            "Epoch [33/50], Step [20/98], Loss: 0.0400\n",
            "Epoch [33/50], Step [30/98], Loss: 0.0531\n",
            "Epoch [33/50], Step [40/98], Loss: 0.0634\n",
            "Epoch [33/50], Step [50/98], Loss: 0.0507\n",
            "Epoch [33/50], Step [60/98], Loss: 0.0456\n",
            "Epoch [33/50], Step [70/98], Loss: 0.1197\n",
            "Epoch [33/50], Step [80/98], Loss: 0.0741\n",
            "Epoch [33/50], Step [90/98], Loss: 0.0481\n",
            "Epoch [33/50] completed in 9.96s\n",
            "Training Loss: 0.0701, Test Accuracy: 91.00%\n",
            "Epoch [34/50], Step [10/98], Loss: 0.0448\n",
            "Epoch [34/50], Step [20/98], Loss: 0.0575\n",
            "Epoch [34/50], Step [30/98], Loss: 0.0721\n",
            "Epoch [34/50], Step [40/98], Loss: 0.0413\n",
            "Epoch [34/50], Step [50/98], Loss: 0.0528\n",
            "Epoch [34/50], Step [60/98], Loss: 0.0571\n",
            "Epoch [34/50], Step [70/98], Loss: 0.0515\n",
            "Epoch [34/50], Step [80/98], Loss: 0.0664\n",
            "Epoch [34/50], Step [90/98], Loss: 0.0709\n",
            "Epoch [34/50] completed in 9.94s\n",
            "Training Loss: 0.0602, Test Accuracy: 90.85%\n",
            "Epoch [35/50], Step [10/98], Loss: 0.0579\n",
            "Epoch [35/50], Step [20/98], Loss: 0.0505\n",
            "Epoch [35/50], Step [30/98], Loss: 0.0533\n",
            "Epoch [35/50], Step [40/98], Loss: 0.0538\n",
            "Epoch [35/50], Step [50/98], Loss: 0.0602\n",
            "Epoch [35/50], Step [60/98], Loss: 0.0430\n",
            "Epoch [35/50], Step [70/98], Loss: 0.0321\n",
            "Epoch [35/50], Step [80/98], Loss: 0.0474\n",
            "Epoch [35/50], Step [90/98], Loss: 0.0417\n",
            "Epoch [35/50] completed in 9.83s\n",
            "Training Loss: 0.0536, Test Accuracy: 92.18%\n",
            "Epoch [36/50], Step [10/98], Loss: 0.0514\n",
            "Epoch [36/50], Step [20/98], Loss: 0.0449\n",
            "Epoch [36/50], Step [30/98], Loss: 0.0338\n",
            "Epoch [36/50], Step [40/98], Loss: 0.0309\n",
            "Epoch [36/50], Step [50/98], Loss: 0.0558\n",
            "Epoch [36/50], Step [60/98], Loss: 0.0324\n",
            "Epoch [36/50], Step [70/98], Loss: 0.0515\n",
            "Epoch [36/50], Step [80/98], Loss: 0.0108\n",
            "Epoch [36/50], Step [90/98], Loss: 0.0395\n",
            "Epoch [36/50] completed in 10.04s\n",
            "Training Loss: 0.0439, Test Accuracy: 91.64%\n",
            "Epoch [37/50], Step [10/98], Loss: 0.0358\n",
            "Epoch [37/50], Step [20/98], Loss: 0.0348\n",
            "Epoch [37/50], Step [30/98], Loss: 0.0188\n",
            "Epoch [37/50], Step [40/98], Loss: 0.0398\n",
            "Epoch [37/50], Step [50/98], Loss: 0.0254\n",
            "Epoch [37/50], Step [60/98], Loss: 0.0490\n",
            "Epoch [37/50], Step [70/98], Loss: 0.0292\n",
            "Epoch [37/50], Step [80/98], Loss: 0.0309\n",
            "Epoch [37/50], Step [90/98], Loss: 0.0404\n",
            "Epoch [37/50] completed in 9.83s\n",
            "Training Loss: 0.0359, Test Accuracy: 91.88%\n",
            "Epoch [38/50], Step [10/98], Loss: 0.0427\n",
            "Epoch [38/50], Step [20/98], Loss: 0.0289\n",
            "Epoch [38/50], Step [30/98], Loss: 0.0187\n",
            "Epoch [38/50], Step [40/98], Loss: 0.0245\n",
            "Epoch [38/50], Step [50/98], Loss: 0.0313\n",
            "Epoch [38/50], Step [60/98], Loss: 0.0286\n",
            "Epoch [38/50], Step [70/98], Loss: 0.0155\n",
            "Epoch [38/50], Step [80/98], Loss: 0.0319\n",
            "Epoch [38/50], Step [90/98], Loss: 0.0188\n",
            "Epoch [38/50] completed in 9.68s\n",
            "Training Loss: 0.0298, Test Accuracy: 91.99%\n",
            "Epoch [39/50], Step [10/98], Loss: 0.0087\n",
            "Epoch [39/50], Step [20/98], Loss: 0.0204\n",
            "Epoch [39/50], Step [30/98], Loss: 0.0207\n",
            "Epoch [39/50], Step [40/98], Loss: 0.0133\n",
            "Epoch [39/50], Step [50/98], Loss: 0.0234\n",
            "Epoch [39/50], Step [60/98], Loss: 0.0307\n",
            "Epoch [39/50], Step [70/98], Loss: 0.0097\n",
            "Epoch [39/50], Step [80/98], Loss: 0.0196\n",
            "Epoch [39/50], Step [90/98], Loss: 0.0226\n",
            "Epoch [39/50] completed in 9.80s\n",
            "Training Loss: 0.0234, Test Accuracy: 92.53%\n",
            "Epoch [40/50], Step [10/98], Loss: 0.0146\n",
            "Epoch [40/50], Step [20/98], Loss: 0.0137\n",
            "Epoch [40/50], Step [30/98], Loss: 0.0105\n",
            "Epoch [40/50], Step [40/98], Loss: 0.0224\n",
            "Epoch [40/50], Step [50/98], Loss: 0.0140\n",
            "Epoch [40/50], Step [60/98], Loss: 0.0184\n",
            "Epoch [40/50], Step [70/98], Loss: 0.0246\n",
            "Epoch [40/50], Step [80/98], Loss: 0.0163\n",
            "Epoch [40/50], Step [90/98], Loss: 0.0093\n",
            "Epoch [40/50] completed in 9.84s\n",
            "Training Loss: 0.0187, Test Accuracy: 92.58%\n",
            "Epoch [41/50], Step [10/98], Loss: 0.0173\n",
            "Epoch [41/50], Step [20/98], Loss: 0.0119\n",
            "Epoch [41/50], Step [30/98], Loss: 0.0162\n",
            "Epoch [41/50], Step [40/98], Loss: 0.0156\n",
            "Epoch [41/50], Step [50/98], Loss: 0.0045\n",
            "Epoch [41/50], Step [60/98], Loss: 0.0130\n",
            "Epoch [41/50], Step [70/98], Loss: 0.0204\n",
            "Epoch [41/50], Step [80/98], Loss: 0.0157\n",
            "Epoch [41/50], Step [90/98], Loss: 0.0115\n",
            "Epoch [41/50] completed in 9.77s\n",
            "Training Loss: 0.0147, Test Accuracy: 92.87%\n",
            "Epoch [42/50], Step [10/98], Loss: 0.0052\n",
            "Epoch [42/50], Step [20/98], Loss: 0.0144\n",
            "Epoch [42/50], Step [30/98], Loss: 0.0125\n",
            "Epoch [42/50], Step [40/98], Loss: 0.0110\n",
            "Epoch [42/50], Step [50/98], Loss: 0.0127\n",
            "Epoch [42/50], Step [60/98], Loss: 0.0292\n",
            "Epoch [42/50], Step [70/98], Loss: 0.0069\n",
            "Epoch [42/50], Step [80/98], Loss: 0.0056\n",
            "Epoch [42/50], Step [90/98], Loss: 0.0041\n",
            "Epoch [42/50] completed in 9.68s\n",
            "Training Loss: 0.0119, Test Accuracy: 93.03%\n",
            "Epoch [43/50], Step [10/98], Loss: 0.0154\n",
            "Epoch [43/50], Step [20/98], Loss: 0.0054\n",
            "Epoch [43/50], Step [30/98], Loss: 0.0096\n",
            "Epoch [43/50], Step [40/98], Loss: 0.0153\n",
            "Epoch [43/50], Step [50/98], Loss: 0.0093\n",
            "Epoch [43/50], Step [60/98], Loss: 0.0050\n",
            "Epoch [43/50], Step [70/98], Loss: 0.0114\n",
            "Epoch [43/50], Step [80/98], Loss: 0.0049\n",
            "Epoch [43/50], Step [90/98], Loss: 0.0087\n",
            "Epoch [43/50] completed in 9.78s\n",
            "Training Loss: 0.0092, Test Accuracy: 93.11%\n",
            "Epoch [44/50], Step [10/98], Loss: 0.0032\n",
            "Epoch [44/50], Step [20/98], Loss: 0.0080\n",
            "Epoch [44/50], Step [30/98], Loss: 0.0069\n",
            "Epoch [44/50], Step [40/98], Loss: 0.0031\n",
            "Epoch [44/50], Step [50/98], Loss: 0.0059\n",
            "Epoch [44/50], Step [60/98], Loss: 0.0039\n",
            "Epoch [44/50], Step [70/98], Loss: 0.0024\n",
            "Epoch [44/50], Step [80/98], Loss: 0.0024\n",
            "Epoch [44/50], Step [90/98], Loss: 0.0032\n",
            "Epoch [44/50] completed in 9.97s\n",
            "Training Loss: 0.0071, Test Accuracy: 93.28%\n",
            "Epoch [45/50], Step [10/98], Loss: 0.0113\n",
            "Epoch [45/50], Step [20/98], Loss: 0.0056\n",
            "Epoch [45/50], Step [30/98], Loss: 0.0088\n",
            "Epoch [45/50], Step [40/98], Loss: 0.0027\n",
            "Epoch [45/50], Step [50/98], Loss: 0.0051\n",
            "Epoch [45/50], Step [60/98], Loss: 0.0114\n",
            "Epoch [45/50], Step [70/98], Loss: 0.0057\n",
            "Epoch [45/50], Step [80/98], Loss: 0.0049\n",
            "Epoch [45/50], Step [90/98], Loss: 0.0055\n",
            "Epoch [45/50] completed in 9.83s\n",
            "Training Loss: 0.0054, Test Accuracy: 93.34%\n",
            "Epoch [46/50], Step [10/98], Loss: 0.0046\n",
            "Epoch [46/50], Step [20/98], Loss: 0.0084\n",
            "Epoch [46/50], Step [30/98], Loss: 0.0108\n",
            "Epoch [46/50], Step [40/98], Loss: 0.0034\n",
            "Epoch [46/50], Step [50/98], Loss: 0.0021\n",
            "Epoch [46/50], Step [60/98], Loss: 0.0070\n",
            "Epoch [46/50], Step [70/98], Loss: 0.0045\n",
            "Epoch [46/50], Step [80/98], Loss: 0.0066\n",
            "Epoch [46/50], Step [90/98], Loss: 0.0066\n",
            "Epoch [46/50] completed in 10.03s\n",
            "Training Loss: 0.0058, Test Accuracy: 93.29%\n",
            "Epoch [47/50], Step [10/98], Loss: 0.0021\n",
            "Epoch [47/50], Step [20/98], Loss: 0.0023\n",
            "Epoch [47/50], Step [30/98], Loss: 0.0028\n",
            "Epoch [47/50], Step [40/98], Loss: 0.0021\n",
            "Epoch [47/50], Step [50/98], Loss: 0.0029\n",
            "Epoch [47/50], Step [60/98], Loss: 0.0069\n",
            "Epoch [47/50], Step [70/98], Loss: 0.0122\n",
            "Epoch [47/50], Step [80/98], Loss: 0.0024\n",
            "Epoch [47/50], Step [90/98], Loss: 0.0062\n",
            "Epoch [47/50] completed in 9.94s\n",
            "Training Loss: 0.0049, Test Accuracy: 93.28%\n",
            "Epoch [48/50], Step [10/98], Loss: 0.0006\n",
            "Epoch [48/50], Step [20/98], Loss: 0.0025\n",
            "Epoch [48/50], Step [30/98], Loss: 0.0024\n",
            "Epoch [48/50], Step [40/98], Loss: 0.0065\n",
            "Epoch [48/50], Step [50/98], Loss: 0.0057\n",
            "Epoch [48/50], Step [60/98], Loss: 0.0032\n",
            "Epoch [48/50], Step [70/98], Loss: 0.0045\n",
            "Epoch [48/50], Step [80/98], Loss: 0.0102\n",
            "Epoch [48/50], Step [90/98], Loss: 0.0089\n",
            "Epoch [48/50] completed in 9.69s\n",
            "Training Loss: 0.0045, Test Accuracy: 93.35%\n",
            "Epoch [49/50], Step [10/98], Loss: 0.0019\n",
            "Epoch [49/50], Step [20/98], Loss: 0.0018\n",
            "Epoch [49/50], Step [30/98], Loss: 0.0019\n",
            "Epoch [49/50], Step [40/98], Loss: 0.0042\n",
            "Epoch [49/50], Step [50/98], Loss: 0.0066\n",
            "Epoch [49/50], Step [60/98], Loss: 0.0034\n",
            "Epoch [49/50], Step [70/98], Loss: 0.0048\n",
            "Epoch [49/50], Step [80/98], Loss: 0.0017\n",
            "Epoch [49/50], Step [90/98], Loss: 0.0115\n",
            "Epoch [49/50] completed in 9.75s\n",
            "Training Loss: 0.0040, Test Accuracy: 93.44%\n",
            "Epoch [50/50], Step [10/98], Loss: 0.0009\n",
            "Epoch [50/50], Step [20/98], Loss: 0.0015\n",
            "Epoch [50/50], Step [30/98], Loss: 0.0079\n",
            "Epoch [50/50], Step [40/98], Loss: 0.0025\n",
            "Epoch [50/50], Step [50/98], Loss: 0.0040\n",
            "Epoch [50/50], Step [60/98], Loss: 0.0015\n",
            "Epoch [50/50], Step [70/98], Loss: 0.0018\n",
            "Epoch [50/50], Step [80/98], Loss: 0.0033\n",
            "Epoch [50/50], Step [90/98], Loss: 0.0043\n",
            "Epoch [50/50] completed in 9.79s\n",
            "Training Loss: 0.0038, Test Accuracy: 93.41%\n",
            "Total training time: 558.52s\n",
            "Final accuracy: 93.41%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved as fast_cifar_model.pth\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Model saved to Google Drive\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "\n",
        "# set random seed\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "# define model component\n",
        "class SEBlock(nn.Module):\n",
        "    \"\"\"Squeeze-and-Excitation block\"\"\"\n",
        "    def __init__(self, channels, reduction=16):\n",
        "        super(SEBlock, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(channels, channels // reduction),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(channels // reduction, channels),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, _, _ = x.size()\n",
        "        y = self.avg_pool(x).view(b, c)\n",
        "        y = self.fc(y).view(b, c, 1, 1)\n",
        "        return x * y.expand_as(x)\n",
        "\n",
        "class DepthwiseSeparableConv(nn.Module):\n",
        "    \"\"\"Depthwise separable convolution\"\"\"\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, bias=False):\n",
        "        super().__init__()\n",
        "        self.depthwise = nn.Conv2d(\n",
        "            in_channels, in_channels, kernel_size,\n",
        "            stride, padding, groups=in_channels, bias=bias\n",
        "        )\n",
        "        self.pointwise = nn.Conv2d(in_channels, out_channels, 1, bias=bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.depthwise(x)\n",
        "        x = self.pointwise(x)\n",
        "        return x\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    \"\"\"Basic residual block\"\"\"\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1, use_se=False, use_ds=False):\n",
        "        super().__init__()\n",
        "        ConvLayer = DepthwiseSeparableConv if use_ds else nn.Conv2d\n",
        "\n",
        "        self.conv1 = ConvLayer(\n",
        "            in_channels, out_channels, kernel_size=3,\n",
        "            stride=stride, padding=1, bias=False\n",
        "        )\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = ConvLayer(\n",
        "            out_channels, out_channels, kernel_size=3,\n",
        "            stride=1, padding=1, bias=False\n",
        "        )\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != self.expansion * out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, self.expansion * out_channels,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion * out_channels)\n",
        "            )\n",
        "\n",
        "        self.se = SEBlock(out_channels) if use_se else nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out = self.se(out)\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "class FastCIFARNet(nn.Module):\n",
        "    \"\"\"Efficient CIFAR-10 classification model\"\"\"\n",
        "    def __init__(self, block, num_blocks, num_classes=10, use_se=True, use_ds=True):\n",
        "        super().__init__()\n",
        "        self.in_channels = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1, use_se=use_se, use_ds=use_ds)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2, use_se=use_se, use_ds=use_ds)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2, use_se=use_se, use_ds=use_ds)\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Linear(256 * block.expansion, num_classes)\n",
        "\n",
        "        self.channel_shuffle = nn.ChannelShuffle(groups=4)\n",
        "\n",
        "    def _make_layer(self, block, out_channels, num_blocks, stride, use_se, use_ds):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(\n",
        "                self.in_channels, out_channels, stride, use_se, use_ds\n",
        "            ))\n",
        "            self.in_channels = out_channels * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Progressive image size training - Use a smaller size in the initial stage\n",
        "        if self.training and x.size(2) > 32:\n",
        "            x = F.interpolate(x, size=(32, 32), mode='bilinear', align_corners=False)\n",
        "\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.channel_shuffle(out)\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.avg_pool(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "def create_model():\n",
        "    \"\"\"Create Model Instrance\"\"\"\n",
        "    return FastCIFARNet(BasicBlock, [5, 5, 5]).to(device)\n",
        "\n",
        "# Data loading and preprocessing\n",
        "def get_data_loaders():\n",
        "    #Data augmentation\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "    ])\n",
        "\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "    ])\n",
        "\n",
        "    # Download dataset\n",
        "    train_set = torchvision.datasets.CIFAR10(\n",
        "        root='./data', train=True, download=True, transform=transform_train)\n",
        "    test_set = torchvision.datasets.CIFAR10(\n",
        "        root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "    # Create Data loader\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_set, batch_size=512, shuffle=True, num_workers=2)\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        test_set, batch_size=512, shuffle=False, num_workers=2)\n",
        "\n",
        "    return train_loader, test_loader\n",
        "\n",
        "# Training\n",
        "def train_model(model, train_loader, test_loader, epochs=50):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    scaler = GradScaler()\n",
        "\n",
        "    # LR scheduler\n",
        "    scheduler = optim.lr_scheduler.OneCycleLR(\n",
        "        optimizer, max_lr=0.01, steps_per_epoch=len(train_loader), epochs=epochs\n",
        "    )\n",
        "\n",
        "    train_losses = []\n",
        "    test_accuracies = []\n",
        "\n",
        "    total_start = time.time()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        epoch_start = time.time()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for i, (inputs, labels) in enumerate(train_loader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Mixed-precision training\n",
        "            with autocast():\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            scheduler.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            if i % 10 == 9:\n",
        "                print(f'Epoch [{epoch+1}/{epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
        "\n",
        "        epoch_time = time.time() - epoch_start\n",
        "        epoch_loss = running_loss / len(train_loader)\n",
        "        train_losses.append(epoch_loss)\n",
        "\n",
        "        # Evaluation\n",
        "        test_acc = evaluate_model(model, test_loader)\n",
        "        test_accuracies.append(test_acc)\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{epochs}] completed in {epoch_time:.2f}s')\n",
        "        print(f'Training Loss: {epoch_loss:.4f}, Test Accuracy: {test_acc:.2f}%')\n",
        "\n",
        "    total_time = time.time() - total_start\n",
        "    print(f'Total training time: {total_time:.2f}s')\n",
        "    print(f'Final accuracy: {test_accuracies[-1]:.2f}%')\n",
        "\n",
        "    # Plot the curve\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(train_losses, label='Training Loss')\n",
        "    plt.title('Training Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(test_accuracies, label='Test Accuracy')\n",
        "    plt.title('Test Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return model\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    return accuracy\n",
        "\n",
        "def main():\n",
        "    train_loader, test_loader = get_data_loaders()\n",
        "\n",
        "    model = create_model()\n",
        "    # print(model)\n",
        "\n",
        "    trained_model = train_model(model, train_loader, test_loader)\n",
        "\n",
        "    torch.save(trained_model.state_dict(), 'fast_cifar_model.pth')\n",
        "    print(\"Model saved as fast_cifar_model.pth\")\n",
        "\n",
        "    # from google.colab import drive\n",
        "    # drive.mount('/content/drive')\n",
        "    # torch.save(trained_model.state_dict(), '/content/drive/MyDrive/fast_cifar_model.pth')\n",
        "    # print(\"Model saved to Google Drive\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    }
  ]
}